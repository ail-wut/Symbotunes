from sklearn.preprocessing import OneHotEncoder
import numpy as np


class FolkTokenizer:
    tokens = [
        "(2",
        "(3",
        "(4",
        "(5",
        "(6",
        "(7",
        "(9",
        "/2",
        "/2<",
        "/2>",
        "/3",
        "/4",
        "/8",
        "12",
        "16",
        "2",
        "2<",
        "2>",
        "3",
        "3/2",
        "3/4",
        "4",
        "4>",
        "5",
        "5/2",
        "6",
        "7",
        "7/2",
        "8",
        "9",
        ":|",
        "<",
        "=A",
        "=A,",
        "=B",
        "=B,",
        "=C",
        "=C,",
        "=D",
        "=E",
        "=E,",
        "=F",
        "=F,",
        "=G",
        "=G,",
        "=a",
        "=b",
        "=c",
        "=c'",
        "=d",
        "=e",
        "=e'",
        "=f",
        "=f'",
        "=g",
        ">",
        "A",
        "A,",
        "B",
        "B,",
        "C",
        "C,",
        "D",
        "D,",
        "E",
        "E,",
        "F",
        "F,",
        "G",
        "G,",
        "K:Cdor",
        "K:Cmaj",
        "K:Cmin",
        "K:Cmix",
        "M:12/8",
        "M:2/4",
        "M:3/2",
        "M:3/4",
        "M:4/4",
        "M:6/8",
        "M:9/8",
        "[",
        "]",
        "^A",
        "^A,",
        "^C",
        "^C,",
        "^D",
        "^F",
        "^F,",
        "^G",
        "^G,",
        "^a",
        "^c",
        "^c'",
        "^d",
        "^f",
        "^f'",
        "^g",
        "_A",
        "_A,",
        "_B",
        "_B,",
        "_C",
        "_D",
        "_E",
        "_E,",
        "_G",
        "_a",
        "_b",
        "_c",
        "_d",
        "_d'",
        "_e",
        "_e'",
        "_g",
        "a",
        "a'",
        "b",
        "b'",
        "c",
        "c'",
        "d",
        "d'",
        "e",
        "e'",
        "f",
        "f'",
        "g",
        "g'",
        "z",
        "|",
        "|1",
        "|2",
        "|:",
    ]

    def __init__(self) -> None:
        self.encoder = OneHotEncoder(categories=[self.tokens], sparse_output=False)

    def __call__(self, data: str):
        # TODO HOE should account for 2 additional tokens <s> and </s> (see Sturm et al.)
        split_str = data.split()
        split_data = np.array(split_str).reshape(-1, 1)
        self.encoder.fit(split_data)
        encoded_categories = self.encoder.transform(split_data)
        return encoded_categories
